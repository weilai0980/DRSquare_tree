{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os \n",
    "import sys \n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "from datetime  import datetime \n",
    "\n",
    "import numpy as np  # learn \n",
    "import pandas as pd # learn\n",
    "from pandas import *\n",
    "from numpy import *\n",
    "\n",
    "from scipy import stats # look at scipy\n",
    "from scipy import linalg\n",
    "from scipy import *\n",
    "\n",
    " \n",
    "import matplotlib as mplt # learn matplolib \n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "import seaborn as sns \n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={\"figure.figsize\": (14, 6)})\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "\n",
    " \n",
    "import sklearn as sk\n",
    "import itertools\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import random\n",
    "import time\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "attri=[\"Year\",\"Month\",\"DayofMonth\",\"DayOfWeek\",\"DepTime\",\"CRSDepTime\",\"ArrTime\",\"CRSArrTime\", 8\n",
    "\"UniqueCarrier\",\"FlightNum\",\"TailNum\",\"ActualElapsedTime\",\"CRSElapsedTime\",\"AirTime\", 6\n",
    "\"ArrDelay\",\"DepDelay\",\"Origin\",\"Dest\",\"Distance\",\"TaxiIn\",\"TaxiOut\",\"Cancelled\",\"CancellationCode\",\"Diverted\", 10\n",
    "\"CarrierDelay\",\"WeatherDelay\",\"NASDelay\",\"SecurityDelay\",\"LateAircraftDelay\"] 5\n",
    "print len(attri)\n",
    "\n",
    "1987,10,14,3,741,730,912,849,\n",
    "PS,1451,NA,91,79,NA,\n",
    "23,11,SAN,SFO,447,NA,NA,0,NA,0,\n",
    "NA,NA,NA,NA,NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data file:  1987\n",
      "(23.0, 1987, 10, 14, 3, 'PS', 1451, 'SAN', 'SFO')\n",
      "1288326\n",
      "1288326\n",
      "feature value set:\n",
      "1\n",
      "3\n",
      "31\n",
      "7\n",
      "14\n",
      "2161\n",
      "237\n",
      "237\n",
      "feature value re-set:\n",
      "(23.0, 1987, 10, 14, 3, 'PS', 1451, 'SAN', 'SFO')\n",
      "[23.0, 0, 0, 20, 2, 10, 154, 11, 150]\n",
      "1288326\n"
     ]
    }
   ],
   "source": [
    "#BT data loading\n",
    "\n",
    "def na_filter(r):\n",
    "    if str(r[14]) == \"NA\" \\\n",
    "    or str(r[0]) == \"NA\" or str(r[1]) == \"NA\" or str(r[2]) == \"NA\"  \\\n",
    "    or str(r[3]) == \"NA\" or str(r[8]) == \"NA\" or str(r[9]) == \"NA\" or str(r[16]) == \"NA\" \\\n",
    "        or str(r[17]) == \"NA\":\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "tdta_rdd= sc.textFile(\"file:///home/tguo/data/tian-real/\"+ \"1987\"  +\".csv\")\n",
    "tdta_rdd.cache()\n",
    "\n",
    "for i in range(1987, 1988):\n",
    "    \n",
    "    raw_rdd = sc.textFile(\"file:///home/tguo/data/tian-real/\"+ str(i)  +\".csv\")\n",
    "    raw_rdd.cache()\n",
    "    header = raw_rdd.first()\n",
    "    raw_rdd = raw_rdd.filter(lambda x:x !=header)    #filter out header\n",
    "    \n",
    "    raw_rdd = raw_rdd.map(lambda line: line.split(\",\")).filter(lambda line: na_filter(line) )\n",
    "#     print raw_rdd.count()    \n",
    "    \n",
    " \n",
    "    \n",
    "    dta_rdd = raw_rdd.map(lambda r: (float(r[14]),\n",
    "                                    int( float(r[0])), \n",
    "                                                                 int(float(r[1])),int(float(r[2])),\n",
    "                                                                 int(float(r[3])),(str(r[8])),\n",
    "                                                                 int(float(r[9])),(str(r[16])),\n",
    "                                                                 (str(r[17])) )\n",
    "                                                                  )\n",
    "    if i == 1987:\n",
    "        tdta_rdd= dta_rdd\n",
    "    else:\n",
    "        tdta_rdd = tdta_rdd.union(dta_rdd)\n",
    "    \n",
    "    print \"data file: \",i\n",
    "    print dta_rdd.first()\n",
    "    print dta_rdd.count()\n",
    "    print tdta_rdd.count()\n",
    "\n",
    "# feature value reset\n",
    "feature_valset=[]\n",
    "feature_valmap=[]\n",
    "feature_num = 8\n",
    "\n",
    "print \"feature value set:\"\n",
    "for i in range(0, feature_num):\n",
    "    feature_valset.append( [] )\n",
    "    feature_valmap.append( {} )\n",
    "    \n",
    "    feature_valset[i]= tdta_rdd.map(lambda line: line[ i+1  ]).distinct().collect()\n",
    "    tmpcnt=len(feature_valset[i])\n",
    "    feature_valmap[i]= dict(zip( feature_valset[i], range(0,tmpcnt)))\n",
    "    \n",
    "    print len(feature_valset[i])\n",
    "\n",
    "print \"feature value re-set:\"\n",
    "# feature value reset\n",
    "def instance_value_reset(line, feature_num ):\n",
    "    tmpline=[]\n",
    "    tmpline.append( line[0] )\n",
    "    for i in range(0,feature_num):\n",
    "        tmpline.append(  feature_valmap[i][line[i+1]] )\n",
    "    return tmpline\n",
    "    \n",
    "dta_reset_rdd = tdta_rdd.map(lambda line: instance_value_reset(line,feature_num))    \n",
    "dta_reset_rdd.cache()\n",
    "\n",
    "print tdta_rdd.first()\n",
    "print dta_reset_rdd.first()\n",
    "print dta_reset_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dta_reset_rdd.map(lambda line: str(line[0])+ \",\" + str(line[1])+ \n",
    "                              \",\" + str(line[2])+ \",\" + str(line[3])+ \n",
    "                              \",\" + str(line[4])+ \",\" + str(line[5])+\n",
    "                              \",\" + str(line[6])+ \",\" + str(line[7])+ \",\"+ str(line[8])).saveAsTextFile(\"hdfs://computer61.ant-net/user/tguo/airline_data_1year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.0,0,0,20,2,10,154,11,150\n"
     ]
    }
   ],
   "source": [
    "dta_rdd = sc.textFile(\"hdfs://computer61.ant-net/user/tguo/airline_data_1year.csv\")\n",
    "print dta_rdd.first()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
