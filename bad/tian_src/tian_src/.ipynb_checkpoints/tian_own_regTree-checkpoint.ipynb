{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os \n",
    "import sys \n",
    "import time\n",
    "import hashlib\n",
    "\n",
    "from datetime  import datetime \n",
    "\n",
    "import numpy as np  # learn \n",
    "import pandas as pd # learn\n",
    "from pandas import *\n",
    "from numpy import *\n",
    "\n",
    "from scipy import stats # look at scipy\n",
    "from scipy import linalg\n",
    "from scipy import *\n",
    "\n",
    " \n",
    "import matplotlib as mplt # learn matplolib \n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "import seaborn as sns \n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={\"figure.figsize\": (14, 6)})\n",
    "\n",
    "import IPython\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "import sklearn as sk\n",
    "import itertools\n",
    "\n",
    "\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(328.0, 10, 10, 2, 2, 8, 1, 3)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dta_RDD = sc.textFile(\"file:///home/tguo/data/tian-test/udpjitter-H1april2014_regTree.csv\")\n",
    "\n",
    "dta_RDD = sc.textFile(\"hdfs://computer61.ant-net/user/tguo/udpjitter-H1april2014_regTree_mllib.csv\")\n",
    "\n",
    "\n",
    "dta_splited = dta_RDD.map(lambda line: line.split(\",\")).map(lambda r:\n",
    "                                                                (float(r[0]),int( float(r[1])), \n",
    "                                                                 int(float(r[2])),int(float(r[3])),\n",
    "                                                                 int(float(r[4])),int(float(r[5])),\n",
    "                                                                 int(float(r[6])),int(float(r[7])) ))\n",
    "dta_splited.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [328.0, 10, 10, 2, 2, 8, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "dta_withNodeIdx = dta_splited.map( lambda r: (0, [r[0], r[1], r[2],r[3],r[4],r[5],r[6],r[7] ] ))\n",
    "\n",
    "print dta_withNodeIdx.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, [328.0, 10, 10, 2, 2, 8, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# for test: randomly assign node index to data points and then aggregate the information of each node\n",
    "\n",
    "dta_withRandomNodeIdx = dta_splited.map( lambda r: (random.randint(0, 7) , [r[0], r[1], r[2],r[3],r[4],r[5],r[6],r[7] ] ))\n",
    "\n",
    "print dta_withRandomNodeIdx.first()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numFeatures=7\n",
    "numFeatureValues = 30\n",
    "\n",
    "\n",
    "def createCombiner_count(line):\n",
    "    featureValue_count=[]\n",
    "    for i in range(0, numFeatures):\n",
    "        featureValue_count.append(  [None] * numFeatureValues  )\n",
    "        featureValue_count[i][ line[i+1]   ] =1\n",
    "    \n",
    "    return featureValue_count\n",
    "\n",
    "def createCombiner_mean(line):\n",
    "    featureValue_mean=[]\n",
    "    for i in range(0, numFeatures):\n",
    "        featureValue_mean.append(  [None] * numFeatureValues  )\n",
    "        featureValue_mean[i][ line[i+1]   ] = float(line[0])*float(line[0])\n",
    "    \n",
    "    return featureValue_mean\n",
    "\n",
    "def createCombiner_var(line):\n",
    "    featureValue_var=[]\n",
    "    for i in range(0, numFeatures):\n",
    "        featureValue_var.append(  [None] * numFeatureValues  )\n",
    "        featureValue_var[i][ line[i+1]   ] = 0\n",
    "    \n",
    "    return featureValue_var\n",
    "    \n",
    "def mergeValue_count( nodeStatis, line ):\n",
    "    for i in range(0, numFeatures):\n",
    "        \n",
    "        if nodeStatis[0][i][line[i+1]] == None:\n",
    "            nodeStatis[0][i][line[i+1]]=1\n",
    "        else:\n",
    "            nodeStatis[0][i][line[i+1]] =  nodeStatis[0][i][line[i+1]]  +1\n",
    "                \n",
    "        \n",
    "def mergeValue_mean(  nodeStatis, line ):\n",
    "    for i in range(0, numFeatures):\n",
    "        \n",
    "        if nodeStatis[1][i][line[i+1]]==None:\n",
    "            nodeStatis[1][i][line[i+1]] = line[0]\n",
    "        else:   \n",
    "            tmpcnt =  nodeStatis[0][i][line[i+1]]\n",
    "                \n",
    "#             nodeStatis[1][i][line[i+1]]=  nodeStatis[1][i][line[i+1]]+ line[0]*line[0]\n",
    "        \n",
    "            nodeStatis[1][i][line[i+1]] = (1.0* nodeStatis[1][i][line[i+1]] * tmpcnt + line[0] )/( 1.0*tmpcnt+1)\n",
    "    \n",
    "def mergeValue_var(  nodeStatis, line ):\n",
    "    for i in range(0, numFeatures):\n",
    "        \n",
    "        if nodeStatis[2][i][line[i+1]]==None:\n",
    "            nodeStatis[2][i][line[i+1]] = 0\n",
    "        else:\n",
    "            tmpcnt =  nodeStatis[0][i][line[i+1]]\n",
    "            tmpmean = nodeStatis[1][i][line[i+1]]\n",
    "        \n",
    "            nodeStatis[2][i][line[i+1]] = nodeStatis[2][i][line[i+1]] + tmpcnt*1.0/ (tmpcnt+1)*( tmpmean- line[0])*( tmpmean- line[0])\n",
    "    \n",
    "def mergeStatis( Statis, line ):\n",
    "    \n",
    "    tmpnodeStatis = Statis\n",
    "    \n",
    "    mergeValue_var(  tmpnodeStatis, line )\n",
    "    \n",
    "    mergeValue_mean(  tmpnodeStatis, line )\n",
    "    \n",
    "    mergeValue_count( tmpnodeStatis, line )\n",
    "    \n",
    "    return tmpnodeStatis\n",
    "    \n",
    "        \n",
    "\n",
    "def mergeStatisCombiner( nodeStatis_1, nodeStatis_2):\n",
    "    \n",
    "    featureValue_var=[]\n",
    "    featureValue_mean=[]\n",
    "    featureValue_cnt=[]\n",
    "    \n",
    "    for i in range(0, numFeatures):\n",
    "        featureValue_var.append(  [None] * numFeatureValues  )\n",
    "        featureValue_mean.append(  [None] * numFeatureValues )\n",
    "        featureValue_cnt.append(  [None] * numFeatureValues  )\n",
    "        \n",
    "        for j in range(0,numFeatureValues):\n",
    "            \n",
    "            if  nodeStatis_1[0][i][j] == None:\n",
    "                featureValue_var[i][j] = nodeStatis_2[2][i][j]    \n",
    "                featureValue_mean[i][j] = nodeStatis_2[1][i][j]    \n",
    "                featureValue_cnt[i][j] = nodeStatis_2[0][i][j]   \n",
    "            elif nodeStatis_2[0][i][j] == None:\n",
    "                featureValue_var[i][j] = nodeStatis_1[2][i][j]    \n",
    "                featureValue_mean[i][j] = nodeStatis_1[1][i][j]    \n",
    "                featureValue_cnt[i][j] = nodeStatis_1[0][i][j]\n",
    "            else:\n",
    "                featureValue_var[i][j] =1.0* nodeStatis_1[2][i][j] +  nodeStatis_2[2][i][j] + \\\n",
    "                ( (1.0* nodeStatis_1[0][i][j]*nodeStatis_2[0][i][j] ) / (1.0*nodeStatis_1[0][i][j]+nodeStatis_2[0][i][j])* \\\n",
    "                 (1.0*nodeStatis_1[1][i][j] - nodeStatis_2[1][i][j])* (1.0*nodeStatis_1[1][i][j] - nodeStatis_2[1][i][j]))     \n",
    "                \n",
    "                featureValue_mean[i][j] = (nodeStatis_1[1][i][j]*nodeStatis_1[0][i][j]+ \\\n",
    "                                           nodeStatis_2[1][i][j]*nodeStatis_2[0][i][j]*1.0)/(1.0* nodeStatis_1[0][i][j]+nodeStatis_2[0][i][j]  )\n",
    "                featureValue_cnt[i][j] = nodeStatis_1[0][i][j]+nodeStatis_2[0][i][j]\n",
    "    \n",
    "    return  (featureValue_cnt, featureValue_mean,featureValue_var) \n",
    "#     return (featureValue_cnt, featureValue_mean,featureValue_var)\n",
    "\n",
    "# (dta_test, test_subset)= dta_withNodeIdx.randomSplit([0.01, 0.2])  \n",
    "\n",
    "# dta_test.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set the data source used for combineByKey            \n",
    "#dta_test= dta_withRandomNodeIdx\n",
    "dta_test= dta_withNodeIdx\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nodeStatis = dta_test.combineByKey(lambda line:(createCombiner_count(line),createCombiner_mean(line),createCombiner_var(line)),\n",
    "                             lambda nodeToFeatureToValue, line: mergeStatis( nodeToFeatureToValue, line ),\n",
    "                             lambda nodeToFeatureToValue_x,nodeToFeatureToValue_y :  mergeStatisCombiner( nodeToFeatureToValue_x, nodeToFeatureToValue_y)\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test for data with random nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_featureValueStatis = nodeStatis.collect()\n",
    "\n",
    "len(tmp_featureValueStatis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 1183355117181.3057, 1476406255809.8943, 1469816683604.5261, 1081083954828.7178, 872692003528.4751, 1723327172181.6946, 812353328557.8132, 1084688276292.0732, 875580157164.638, 1025494970482.4362, 1285793040251.6587, 761456551611.4243, 1465076041959.278, 1284544704136.01, 1275060934797.3792, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "#1st dim: node index ; 2nd dim: Y and feature part of a data point ; 3rd dim: cnt or mean or variance ; \n",
    "#4rd dim: feature index  \n",
    "\n",
    "print tmp_featureValueStatis[0][1][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 795.1419707996299, 867.2707011813832, 807.6376688199917, 762.1448179676271, 768.0810533140937, 1371.4210998690774, 772.4156809840484, 752.0882264229083, 739.339701172516, 757.9155086631944, 756.255812279241, 783.8165137614691, 809.5179718501533, 848.2858859049458, 903.6685162286794, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print tmp_featureValueStatis[0][1][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 221778, 222282, 221982, 221554, 219004, 216153, 220152, 222133, 222001, 223301, 222245, 220398, 217479, 220588, 224017, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print tmp_featureValueStatis[0][1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "lambda cannot contain assignment (<ipython-input-127-ffe2e744843e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-127-ffe2e744843e>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    dta_test.map(lambda line: line[1][1]).map(lambda val: cnt_dict[val]= cnt_dict[val]+1 )\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m lambda cannot contain assignment\n"
     ]
    }
   ],
   "source": [
    "cnt_dict={}\n",
    "\n",
    "def \n",
    "\n",
    "dta_test.map(lambda line: line[1][1]).map(lambda val: cnt_dict[val]= cnt_dict[val]+1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp=[[]]\n",
    "# tmp.append([])\n",
    "# tmp[0].append(1)\n",
    "# print tmp[0][0]\n",
    "\n",
    "\n",
    "# def func(arr):\n",
    "#     arr.append(1)\n",
    "\n",
    "# func(tmp)\n",
    "# print tmp\n",
    "\n",
    "\n",
    "tmp1=[]\n",
    "tmp2=[]\n",
    "\n",
    "tmp1.append(3)\n",
    "tmp2.append(4)\n",
    "\n",
    "tmptuple= (tmp1, tmp2 )\n",
    "\n",
    "tmptuple[0][0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, [[[1], []]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class nodeToFeatureValue:\n",
    "    \n",
    "    featureToValue = [[]]\n",
    "    featureNum = 0\n",
    "    featureValues = []\n",
    "    \n",
    "    def __init__(self, line):\n",
    "        self.featureNum=100\n",
    "\n",
    "\n",
    "class nodeFeaturesLabel:    \n",
    "    node=0.0\n",
    "    features = []\n",
    "    label= 0.0\n",
    "    \n",
    "    def __init__(self, node, features,label):\n",
    "            self.node = node\n",
    "            self.label= label\n",
    "            size=len(features)\n",
    "            for i in range(0,size):\n",
    "                self.features[i]= features[i]\n",
    "\n",
    "                \n",
    "def getFeatureVector(line):\n",
    "    tmpfea=[]\n",
    "    for i in range(0,numFeatures):\n",
    "        tmpfea.append(line[i+2])\n",
    "    return tmpfea\n",
    "\n",
    "    \n",
    "def nodeFeaturesLabel_object(line):\n",
    "    tmp=nodeFeaturesLabel(line[0],  getFeatureVector(line), line[1])\n",
    "    return tmp\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000, 2, 3, 4, 10]\n"
     ]
    }
   ],
   "source": [
    "a=[1,2,3,4]\n",
    "\n",
    "def func(tmplist):\n",
    "    loclist= tmplist\n",
    "    loclist.append(10)\n",
    "    loclist[0]=1000\n",
    "    return loclist\n",
    "\n",
    "b= func(a)\n",
    "print b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
